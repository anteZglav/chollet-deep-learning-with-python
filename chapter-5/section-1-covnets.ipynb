{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1Test covnets\n",
    "## Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Load.\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Reshape images.\n",
    "train_images = train_images.reshape((train_images.shape[0], 28, 28, 1))\n",
    "train_images = train_images.astype('float32')/255\n",
    "test_images = test_images.reshape((test_images.shape[0], 28, 28, 1))\n",
    "test_images = test_images.astype('float32')/255\n",
    "\n",
    "# Convert labels to categorical.\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# Split validation and train.\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_labels= model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This is number[1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20ed3792400>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAADAdJREFUeJzt3V2oZXUZx/Hvk9mNdaGE02DWVEgUQhoHCYycIRSLYOwiyYuYKDpdKCR0kXgzZ4hAoterYMKhCcwK1BwiypBxLAhxlPClyRdkqmmGmURBuwr16eKsidN4zl777LXWXnvm+X5g2Huv/bIelv7OWnv/1389kZlIquctYxcgaRyGXyrK8EtFGX6pKMMvFWX4paIMv1SU4ZeKMvxSUW+d58oiwtMJpYFlZkzzuk57/oi4PiKeiYjnI+K2Lp8lab5i1nP7I+I84FngWuAY8ChwU2b+ZcJ73PNLA5vHnv8q4PnMfCEz/wP8HNjZ4fMkzVGX8F8C/GPN42PNsv8TEcsRcTgiDndYl6SedfnBb71Dizcd1mfmXmAveNgvLZIue/5jwKVrHr8bON6tHEnz0iX8jwKXRcT7IuJtwOeBA/2UJWloMx/2Z+ZrEXEL8DvgPGBfZj7dW2WSBjXzUN9MK/M7vzS4uZzkI+nsZfilogy/VJThl4oy/FJRhl8qyvBLRRl+qSjDLxVl+KWiDL9UlOGXijL8UlGGXyrK8EtFGX6pKMMvFWX4paIMv1SU4ZeKMvxSUXNt0S2tdfDgwYnPb9++feLze/bsmfj8ysrKJiuqxT2/VJThl4oy/FJRhl8qyvBLRRl+qSjDLxXVqUtvRBwFXgVeB17LzKWW19ulV/8zzw7RZ9qxY8fE5x966KH5FDKAabv09nGSz47MfLGHz5E0Rx72S0V1DX8CD0TEYxGx3EdBkuaj62H/1Zl5PCIuBn4fEX/NzIfXvqD5o+AfBmnBdNrzZ+bx5vYUcB9w1Tqv2ZuZS20/Bkqar5nDHxEXRMQ7Tt8HrgOe6qswScPqcti/BbgvIk5/zs8y87e9VCVpcDOHPzNfAD7SYy06B7XNyZ+kbaz90KFDE5/fvXv3hs+11XU2j/NPy6E+qSjDLxVl+KWiDL9UlOGXijL8UlGdpvRuemVO6S1n0uW524bbuk677Thdfeb3jm3aKb3u+aWiDL9UlOGXijL8UlGGXyrK8EtFGX6pKFt0q5O2NtiTxvLbWmxXmFY7Jvf8UlGGXyrK8EtFGX6pKMMvFWX4paIMv1SU4/zq5Jprrpn5vW3nCLQZ8rLgFbjnl4oy/FJRhl8qyvBLRRl+qSjDLxVl+KWiWsf5I2If8BngVGZe3iy7CPgFsA04CtyYmS8PV6bG0jaW3mWsvasu625r713BNHv+nwDXn7HsNuDBzLwMeLB5LOks0hr+zHwYeOmMxTuB/c39/cANPdclaWCzfuffkpknAJrbi/srSdI8DH5uf0QsA8tDr0fS5sy65z8ZEVsBmttTG70wM/dm5lJmLs24LkkDmDX8B4Bdzf1dwP39lCNpXlrDHxF3A38CPhgRxyLiy8AdwLUR8RxwbfNY0lkkuvQw3/TKIua3MvWi6/8fk+bN79ixo9NnHzx4cOb3dl33IsvMmOZ1nuEnFWX4paIMv1SU4ZeKMvxSUYZfKspLd5/j2qa9dhkum8akIbW22nbv3j3x+bb3n8vDeX1wzy8VZfilogy/VJThl4oy/FJRhl8qyvBLRTnOfw6Y57TsM+3Zs2fi85PG4rueY9DWZts23JO555eKMvxSUYZfKsrwS0UZfqkowy8VZfilohznPwusrKzM/N6uY91DtuBuO0egTZftIvf8UlmGXyrK8EtFGX6pKMMvFWX4paIMv1RUa4vuiNgHfAY4lZmXN8tWgK8A/2pedntm/qZ1ZbboXlfbeHXb9esnjeW3jaW3zalvO0/Aa+Mvnj5bdP8EuH6d5d/PzCuaf63Bl7RYWsOfmQ8DL82hFklz1OU7/y0R8URE7IuIC3urSNJczBr+HwEfAK4ATgDf3eiFEbEcEYcj4vCM65I0gJnCn5knM/P1zHwD+DFw1YTX7s3MpcxcmrVISf2bKfwRsXXNw88CT/VTjqR5aZ3SGxF3A9uBd0bEMWA3sD0irgASOAp8dcAaJQ2gNfyZedM6i+8coJZzVtdx/Lax+kmf33XO+6FDhzq9X4vLM/ykogy/VJThl4oy/FJRhl8qyvBLRXnp7h60Xd56yKE8aVbu+aWiDL9UlOGXijL8UlGGXyrK8EtFGX6pqNZLd/e6srP40t2TxvLbLn/dJmKqKy3PpOt/3yFr0zD6vHS3pHOQ4ZeKMvxSUYZfKsrwS0UZfqkowy8V5Xz+KbXN2Z9k6DbWXeb7t7Xg1rnLPb9UlOGXijL8UlGGXyrK8EtFGX6pKMMvFdU6nz8iLgV+CrwLeAPYm5k/jIiLgF8A24CjwI2Z+XLLZ5218/m7zIvvOie+7RyDSdcTaBvHH/ocBM1fn/P5XwO+npkfAj4G3BwRHwZuAx7MzMuAB5vHks4SreHPzBOZ+Xhz/1XgCHAJsBPY37xsP3DDUEVK6t+mvvNHxDbgSuARYEtmnoDVPxDAxX0XJ2k4U5/bHxFvB+4Bbs3MV6b9HhsRy8DybOVJGspUe/6IOJ/V4N+Vmfc2i09GxNbm+a3AqfXem5l7M3MpM5f6KFhSP1rDH6u7+DuBI5n5vTVPHQB2Nfd3Aff3X56koUxz2H818AXgyYj4c7PsduAO4JcR8WXg78DnhilxPrpM2e2qbUpuW4vvSdraf6uu1vBn5h+Bjb7gf7LfciTNi2f4SUUZfqkowy8VZfilogy/VJThl4qyRfeU5rmdNss22lrLFt2SJjL8UlGGXyrK8EtFGX6pKMMvFWX4paJs0T2lSZe4brsWQNt8fC+vrTG455eKMvxSUYZfKsrwS0UZfqkowy8VZfilopzPL51jnM8vaSLDLxVl+KWiDL9UlOGXijL8UlGGXyqqNfwRcWlEHIyIIxHxdER8rVm+EhH/jIg/N/8+PXy5kvrSepJPRGwFtmbm4xHxDuAx4AbgRuDfmfmdqVfmST7S4KY9yaf1Sj6ZeQI40dx/NSKOAJd0K0/S2Db1nT8itgFXAo80i26JiCciYl9EXLjBe5Yj4nBEHO5UqaReTX1uf0S8HTgEfCsz742ILcCLQALfZPWrwZdaPsPDfmlg0x72TxX+iDgf+DXwu8z83jrPbwN+nZmXt3yO4ZcG1tvEnlhtAXsncGRt8JsfAk/7LPDUZouUNJ5pfu3/OPAH4EngjWbx7cBNwBWsHvYfBb7a/Dg46bPc80sD6/Wwvy+GXxqe8/klTWT4paIMv1SU4ZeKMvxSUYZfKsrwS0UZfqkowy8VZfilogy/VJThl4oy/FJRhl8qqvUCnj17EfjbmsfvbJYtokWtbVHrAmubVZ+1vXfaF851Pv+bVh5xODOXRitggkWtbVHrAmub1Vi1edgvFWX4paLGDv/ekdc/yaLWtqh1gbXNapTaRv3OL2k8Y+/5JY1klPBHxPUR8UxEPB8Rt41Rw0Yi4mhEPNl0Hh61xVjTBu1URDy1ZtlFEfH7iHiuuV23TdpItS1E5+YJnaVH3XaL1vF67of9EXEe8CxwLXAMeBS4KTP/MtdCNhARR4GlzBx9TDgiPgH8G/jp6W5IEfFt4KXMvKP5w3lhZn5jQWpbYZOdmweqbaPO0l9kxG3XZ8frPoyx578KeD4zX8jM/wA/B3aOUMfCy8yHgZfOWLwT2N/c38/q/zxzt0FtCyEzT2Tm4839V4HTnaVH3XYT6hrFGOG/BPjHmsfHWKyW3wk8EBGPRcTy2MWsY8vpzkjN7cUj13Om1s7N83RGZ+mF2XazdLzu2xjhX6+byCINOVydmR8FPgXc3Bzeajo/Aj7Aahu3E8B3xyym6Sx9D3BrZr4yZi1rrVPXKNttjPAfAy5d8/jdwPER6lhXZh5vbk8B97H6NWWRnDzdJLW5PTVyPf+TmScz8/XMfAP4MSNuu6az9D3AXZl5b7N49G23Xl1jbbcxwv8ocFlEvC8i3gZ8HjgwQh1vEhEXND/EEBEXANexeN2HDwC7mvu7gPtHrOX/LErn5o06SzPytlu0jtejnOTTDGX8ADgP2JeZ35p7EeuIiPezureH1RmPPxuztoi4G9jO6qyvk8Bu4FfAL4H3AH8HPpeZc//hbYPatrPJzs0D1bZRZ+lHGHHb9dnxupd6PMNPqskz/KSiDL9UlOGXijL8UlGGXyrK8EtFGX6pKMMvFfVfgFbUFeQIWBkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "index = np.random.randint(0,test_images.shape[0])\n",
    "print(f\" This is number{np.nonzero(result_labels[index]>0.5)[0]}\")\n",
    "plt.imshow(test_images[index].reshape((28,28)),plt.cm.gray)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This is number[5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20ed25b22e8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAADVVJREFUeJzt3X/oXfV9x/HXy1hRTAnGahKtXbooZhLQaojThpkxUp0UYomRBoSM6VKk4gr7Y6JIg6NYZttNFIopCU2ltQ1oNTS6NsiYHcyQGLX5ZVst3yWZIVlMsSYqwfjeH9+T8W383s/55t5z77nfvJ8PCN97z/vec95cfX3Pud/POefjiBCAfM5ouwEA7SD8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSOnOQG7PN6YRAn0WEJ/K6nvb8tm+y/Wvbb9i+t5d1ARgsd3tuv+0pkn4jabGkfZK2SFoeEbsK72HPD/TZIPb8CyS9ERG/i4hjkn4saUkP6wMwQL2E/2JJe8c831ct+yO2V9reantrD9sC0LBe/uA33qHFxw7rI2K1pNUSh/3AMOllz79P0iVjnn9a0lu9tQNgUHoJ/xZJl9n+rO2zJH1Z0oZm2gLQb10f9kfEh7bvlvRzSVMkrY2InY11BqCvuh7q62pjfOcH+m4gJ/kAmLwIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSKrrKbolyfaIpHclHZf0YUTMb6IpAP3XU/grfxkRhxpYD4AB4rAfSKrX8IekX9h+2fbKJhoCMBi9HvZ/PiLesn2hpE22X4+IF8e+oPqlwC8GYMg4IppZkb1K0pGI+FbhNc1sDEBHEeGJvK7rw37b59r+5InHkr4gaUe36wMwWL0c9s+Q9FPbJ9bzo4j4t0a6AtB3jR32T2hjHPYDfdf3w34AkxvhB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gqSbu3otJbObMmcX64sWLi/VDh8o3bn7++edPuadBmD59erE+d+7cYv3WW28t1hctWlSsr1zZ+c52W7duLb63Kez5gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApxvmTu+OOO4r1Bx98sFjftGlTsf7++++fck8nTJs2rVi/4YYbivWrr766Y+2KK64ovvf8888v1nu1Zs2ajrUrr7yyr9s+gT0/kBThB5Ii/EBShB9IivADSRF+ICnCDyRVO0W37bWSvijpYETMq5ZNl/QTSbMljUi6LSJ+X7sxpugeuLvuuqtYf+SRR4r1KVOm9LR9u/Ns0YOcHv5kpb6k3nvbvn17sX7//fd3rG3cuLGnbTc5Rff3Jd100rJ7Jb0QEZdJeqF6DmASqQ1/RLwo6fBJi5dIWlc9Xifplob7AtBn3X7nnxER+yWp+nlhcy0BGIS+n9tve6WkzjcsA9CKbvf8B2zPkqTq58FOL4yI1RExPyLmd7ktAH3Qbfg3SFpRPV4h6dlm2gEwKLXht/2kpP+SdLntfbbvkPRNSYtt/1bS4uo5gEmkdpy/0Y0xzt8XN954Y8da2/fNL42nHzt2rPje48ePF+tbtmwp1t98882Otb179xbf+8orrxTr27ZtK9br5jN47733ivVeNDnOD+A0RPiBpAg/kBThB5Ii/EBShB9IiqG+08CuXbs61i6//PKe1v3cc88V6+vXry/W9+zZ07H29ttvF9975MiRYn1kZKRYz4qhPgBFhB9IivADSRF+ICnCDyRF+IGkCD+QFFN0D4GpU6cW6w899FCxPnfu3I61Xs/jeOKJJ4r1unF+DC/2/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFNfzD4HHH3+8WL/zzjuL9X5Og/3BBx8U6w8//HCxvmrVqp62j1PH9fwAigg/kBThB5Ii/EBShB9IivADSRF+IKnacX7bayV9UdLBiJhXLVsl6e8k/W/1svsionyDd+Ud5583b16xXjcd9BlnlH9Hl8b5jx49Wnxv6b76UvleAZK0efPmYv36668v1tG8Jsf5vy/ppnGW/0tEXFX9qw0+gOFSG/6IeFHS4QH0AmCAevnOf7ftX9lea/u8xjoCMBDdhv+7kuZIukrSfknf7vRC2yttb7W9tcttAeiDrsIfEQci4nhEfCTpe5IWFF67OiLmR8T8bpsE0Lyuwm971pinX5K0o5l2AAxK7a27bT8paZGkT9neJ+nrkhbZvkpSSBqR9JU+9gigD7iefwCmTZtWrC9btqxYrxsrf+yxxzrWtm3bVnzvtddeW6xv2rSpWK+bc+C6667rWKs7RwDd4Xp+AEWEH0iK8ANJEX4gKcIPJEX4gaQY6kvu0ksvLdZfe+21Yv3ss88u1pcuXdqx9swzzxTfi+4w1AegiPADSRF+ICnCDyRF+IGkCD+QFOEHkqq9nh+T2wUXXFCsP/DAA8V63Tj+O++8U6y//vrrxTraw54fSIrwA0kRfiApwg8kRfiBpAg/kBThB5JinP80cOaZnf8z1o3j33777T1t+9FHHy3WGecfXuz5gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiCp2vv2275E0g8kzZT0kaTVEfGI7emSfiJptqQRSbdFxO9r1nVa3rd/4cKFxfr27duL9bpr4uvMnTu3Y23nzp09rbtunH7BggXF+tGjR3vaPk5dk/ft/1DSP0TEn0n6c0lftX2FpHslvRARl0l6oXoOYJKoDX9E7I+IbdXjdyXtlnSxpCWS1lUvWyfpln41CaB5p/Sd3/ZsSZ+TtFnSjIjYL43+gpB0YdPNAeifCZ/bb3uqpKckfS0i/mBP6GuFbK+UtLK79gD0y4T2/LY/odHg/zAinq4WH7A9q6rPknRwvPdGxOqImB8R85toGEAzasPv0V38Gkm7I+I7Y0obJK2oHq+Q9Gzz7QHol4kM9S2U9EtJ2zU61CdJ92n0e/96SZ+RtEfSsog4XLOuSTvU99JLL3Ws1Q139Wrjxo3F+jXXXNOxNnPmzOJ764YCly9fXqzv2LGjWMfgTXSor/Y7f0T8p6ROK/urU2kKwPDgDD8gKcIPJEX4gaQIP5AU4QeSIvxAUty6e4JeffXVjrW6abDPOuusYv2iiy4q1m+++eZivXSqdd3lwvfcc0+xzjj+6Ys9P5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kVXs9f6Mbm8TX8/finHPOKdaXLl1arM+ZM6frbe/evbtYX79+fdfrxnBq8tbdAE5DhB9IivADSRF+ICnCDyRF+IGkCD+QFOP8wGmGcX4ARYQfSIrwA0kRfiApwg8kRfiBpAg/kFRt+G1fYvvfbe+2vdP231fLV9n+H9uvVv/KN5cHMFRqT/KxPUvSrIjYZvuTkl6WdIuk2yQdiYhvTXhjnOQD9N1ET/KpnbEnIvZL2l89ftf2bkkX99YegLad0nd+27MlfU7S5mrR3bZ/ZXut7fM6vGel7a22t/bUKYBGTfjcfttTJf2HpG9ExNO2Z0g6JCkk/ZNGvxr8bc06OOwH+myih/0TCr/tT0j6maSfR8R3xqnPlvSziJhXsx7CD/RZYxf2eHQK2DWSdo8NfvWHwBO+JInpXIFJZCJ/7V8o6ZeStkv6qFp8n6Tlkq7S6GH/iKSvVH8cLK2LPT/QZ40e9jeF8AP9x/X8AIoIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSdXewLNhhyT995jnn6qWDaNh7W1Y+5LorVtN9vYnE33hQK/n/9jG7a0RMb+1BgqGtbdh7Uuit2611RuH/UBShB9Iqu3wr255+yXD2tuw9iXRW7da6a3V7/wA2tP2nh9AS1oJv+2bbP/a9hu2722jh05sj9jeXs083OoUY9U0aAdt7xizbLrtTbZ/W/0cd5q0lnobipmbCzNLt/rZDduM1wM/7Lc9RdJvJC2WtE/SFknLI2LXQBvpwPaIpPkR0fqYsO2/kHRE0g9OzIZk+58lHY6Ib1a/OM+LiH8ckt5W6RRnbu5Tb51mlv4btfjZNTnjdRPa2PMvkPRGRPwuIo5J+rGkJS30MfQi4kVJh09avETSuurxOo3+zzNwHXobChGxPyK2VY/flXRiZulWP7tCX61oI/wXS9o75vk+DdeU3yHpF7Zftr2y7WbGMePEzEjVzwtb7udktTM3D9JJM0sPzWfXzYzXTWsj/OPNJjJMQw6fj4irJf21pK9Wh7eYmO9KmqPRadz2S/p2m81UM0s/JelrEfGHNnsZa5y+Wvnc2gj/PkmXjHn+aUlvtdDHuCLirernQUk/1ejXlGFy4MQkqdXPgy338/8i4kBEHI+IjyR9Ty1+dtXM0k9J+mFEPF0tbv2zG6+vtj63NsK/RdJltj9r+yxJX5a0oYU+Psb2udUfYmT7XElf0PDNPrxB0orq8QpJz7bYyx8ZlpmbO80srZY/u2Gb8bqVk3yqoYx/lTRF0tqI+MbAmxiH7T/V6N5eGr3i8Udt9mb7SUmLNHrV1wFJX5f0jKT1kj4jaY+kZREx8D+8dehtkU5x5uY+9dZpZunNavGza3LG60b64Qw/ICfO8AOSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kNT/AQDiFstpKXn/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "index = np.random.randint(0,train_images.shape[0])\n",
    "print(f\" This is number{np.nonzero(train_labels[index])[0]}\")\n",
    "plt.imshow(train_images[index].reshape((28,28)),plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model\n",
    "Convolutional networks recieve inputs of shape \\[height, width, channels\\]. When creating a layer the first parameter is the number of output channels. while the second is the shape of the convolutional window.\n",
    "\n",
    "Max polling shrinks the input layer by applying max over it's window size.\n",
    "\n",
    "After convolutional layer which will extract features from the image we should use a classifier made from stacks of dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\azglav\\Anaconda3\\envs\\chollet-deep-learning-with-python\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "# NOTE: input is a 4D tensor: batch, height, width, channels.\n",
    "model = models.Sequential()\n",
    "# ConvNet part of the model. \n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1))) \n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Classifier part.\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile.\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print the summary of the model.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\azglav\\Anaconda3\\envs\\chollet-deep-learning-with-python\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 44s 726us/step - loss: 0.1782 - acc: 0.9428\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 42s 692us/step - loss: 0.0493 - acc: 0.9850\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 43s 719us/step - loss: 0.0329 - acc: 0.9894\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 42s 703us/step - loss: 0.0246 - acc: 0.9921\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 42s 701us/step - loss: 0.0194 - acc: 0.9938\n",
      "10000/10000 [==============================] - 3s 260us/step\n",
      "Test [loss, accuracy]:[0.027935, 99.10 %]\n"
     ]
    }
   ],
   "source": [
    "# Train.\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)\n",
    "test_loss, test_acc = model.evaluate(test_images,test_labels)\n",
    "print(f\"Test [loss, accuracy]:[{test_loss:.6f}, {test_acc * 100:.2f} %]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temperature forcasting with RNNS\n",
    "\n",
    "Download data from bgc institut in jenna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip\n",
    "# !curl -O https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip\n",
    "# !unzip jena_climate_2009_20016.csv  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Date Time\"\n",
      "\"p (mbar)\"\n",
      "\"T (degC)\"\n",
      "\"Tpot (K)\"\n",
      "\"Tdew (degC)\"\n",
      "\"rh (%)\"\n",
      "\"VPmax (mbar)\"\n",
      "\"VPact (mbar)\"\n",
      "\"VPdef (mbar)\"\n",
      "\"sh (g/kg)\"\n",
      "\"H2OC (mmol/mol)\"\n",
      "\"rho (g/m**3)\"\n",
      "\"wv (m/s)\"\n",
      "\"max. wv (m/s)\"\n",
      "\"wd (deg)\"\n",
      "The data contains 420551 samples.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "data_dir = 'datasets/'\n",
    "fname = os.path.join(data_dir,'jena_climate_2009_2016.csv')\n",
    "\n",
    "with open(fname) as F:\n",
    "    data= F.read()\n",
    "# seperate lines from heder \n",
    "lines = data.split('\\n')\n",
    "header = lines[0].split(',')\n",
    "lines = lines[1:]\n",
    "# Print header and length.\n",
    "print('\\n'.join(header))\n",
    "print(f\"The data contains {len(lines)} samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "float_data = np.zeros((len(lines), len(header)-1))\n",
    "for i, line in enumerate(lines):\n",
    "    values = [float(x)for x in line.split(',')[1:]]\n",
    "    float_data[i, :] = values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "temp = float_data[:, 1]\n",
    "plt.plot(temp)\n",
    "plt.title('Temperature')\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0,1440)*10/60/24, temp[:1440])\n",
    "plt.title('Temperature in the first 10 days')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* lookback = 720 - 5 days\n",
    "* steps = 6 -hourly sample rate(the data comes in 10 min intervals)\n",
    "* delay 144 - predict next 24 hours\n",
    "\n",
    "Since we will be lookingat the data throughasliding window we will use agenerator as not to duplicate the data(although numpy would probably take care of this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0:200000 -training data\n",
    "mean = float_data[:200000].mean(axis=0)\n",
    "float_data -= mean\n",
    "std = float_data[:200000].std(axis=0)\n",
    "float_data /= std "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(data, lookback, delay, min_index, max_index,\n",
    "              shuffle=False, batch_size=128, step=6):\n",
    "    if max_index is None:\n",
    "        max_index = len(data) - delay - 1\n",
    "    i= min_index + lookback\n",
    "    while 1:\n",
    "        if shuffle:\n",
    "            rows = np.random.randint(min_index + lookback,\n",
    "                                    max_index, size=batch_size)\n",
    "        else:\n",
    "            if i + batchsize >= max_index:\n",
    "                i= min_index + lookback\n",
    "            rows = np.arange(i, min(i + batchsize,max_index))\n",
    "            i += len(rows)\n",
    "        samples = np.zeros((len(rows), lookback // step, data.shape[-1]))\n",
    "        targets = np.zeros((len(rows),))\n",
    "        for j, row in enumerate(rows):\n",
    "            indices = range(rows[j] - lookback, rows[j], step)\n",
    "            samples[j] = data[indices]\n",
    "            targets[j] = data[rows[j] + delay][1] # Only temperature is the target.\n",
    "        yield samples, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback = 1440\n",
    "step = 6\n",
    "delay= 144\n",
    "batch_size = 128\n",
    "train_gen = generator(float_data, lookback=lookback, delay=delay,\n",
    "                      min_index=0, max_index=200000, shuffle=True,\n",
    "                      step=step, batch_size=batch_size)\n",
    "val_gen   = generator(float_data, lookback=lookback, delay=delay,\n",
    "                      min_index=200001, max_index=300000, shuffle=True,\n",
    "                      step=step, batch_size=batch_size)\n",
    "test_gen = generator(float_data, lookback=lookback, delay=delay,\n",
    "                      min_index=300001, max_index=None, shuffle=True,\n",
    "                      step=step, batch_size=batch_size)\n",
    "val_steps = (300000 - 200001 - lookback)\n",
    "val_steps = (len(float_data) - 300001 - lookback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive MAE 0.28849283149608074\n",
      "Navie MAE in C 2.553882526041667\n"
     ]
    }
   ],
   "source": [
    "# Common sense baseline:\n",
    "#   Supose temperature is the same as before 24 h.\n",
    "\n",
    "def evaluate_naive_method():\n",
    "    batch_maes = []\n",
    "    for step in range(3000):\n",
    "        samples, targets = next(val_gen)\n",
    "        preds = samples[:, -1, 1]\n",
    "        mae = np.mean(np.abs(preds - targets))\n",
    "        batch_maes.append(mae)\n",
    "    print(f\"Naive MAE {np.mean(batch_maes)}\")\n",
    "    print(f\"Navie MAE in C {np.mean(batch_maes) * std[1]}\")\n",
    "evaluate_naive_method()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Flatten(input_shape=(lookback//step,float_data.shape[-1])))\n",
    "model.add(layers.Dense(32,activation='relu'))\n",
    "model.add(layers.Dense(1))\n",
    "model.compile(optimizer=RMSprop(),loss='mae')\n",
    "history = model.fit_generator(train_gen,\n",
    "                             steps_per_epoch=500,\n",
    "                             epochs=20,\n",
    "                             validation_data=val_gen,\n",
    "                             validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    def plot_history_record(history, record, *args, **kwargs):\n",
    "        values = history.history[record]\n",
    "        epochs = range(1, len(values) + 1)\n",
    "        plt.plot(epochs, values, *args, **kwargs)\n",
    "\n",
    "    plot_history_record(history, 'loss', 'bo', label='Training loss')\n",
    "    plot_history_record(history, 'val_loss', 'b', label='Validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plot_history_record(history, 'acc', 'bo', label='Training accuracy')\n",
    "    plot_history_record(history, 'val_acc', 'b', label='Validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 240, 14)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples, targets = next(val_gen)\n",
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable int object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-48bfbf1cbdc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable int object"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
